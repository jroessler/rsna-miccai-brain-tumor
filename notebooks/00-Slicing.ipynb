{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17c4df0b-8f20-49bc-9e75-fcc5e3985edd",
   "metadata": {},
   "source": [
    "# Slicing Techniques\n",
    "\n",
    "In this notebook we will pre-process the images with different slicing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f890c327-af46-4b0a-ae4f-66b0b1eb80e1",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7beefc9-1c77-469d-aa86-0852ce4d8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mclahe import mclahe\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "import imageio\n",
    "\n",
    "import torchio as tio\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69032e1-e9c2-42b2-ad4b-41828b74a756",
   "metadata": {},
   "source": [
    "#### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57758aa8-de49-474a-b7b9-23fc743a24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8107517f-c4e6-4bbc-97b3-dfbd46c72a1d",
   "metadata": {},
   "source": [
    "#### Load Data Set and Select Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c11bc-e6b0-4a6f-abdf-38c0e084599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../train_labels.csv\")\n",
    "sample_patients = ['00002', '00457', '00601', '00003', '00222', '00397', '00121', '00804', '00266', '00581']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79c6df0-fc71-436a-ab9e-359fdf4dfdc7",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3378f1-c188-495d-978a-ba7f96ab48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b193d-d70f-4eb4-92bc-0328d33a53a5",
   "metadata": {},
   "source": [
    "## 1. No Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc7dbb-4714-42e3-b8d7-ecfcf2ad6a1f",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb5c48-d181-4483-b859-551b7d7a6bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    REMOVE_BLACK_BOUNDARIES = False,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ace1-a624-45dd-a40a-18dcd36d340b",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a67c0-30f1-4072-88e8-d89c4f346ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7aedeb-df7f-45a4-9646-97bde2c10c19",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac52114-47e8-47a4-b915-0e6c4972cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec6f51-ff10-46d5-a325-e90acd1e00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(img):\n",
    "    (x, y) = np.where(img > 0)\n",
    "    if len(x) > 0 and len(y) > 0:\n",
    "        x_mn = np.min(x)\n",
    "        x_mx = np.max(x)\n",
    "        y_mn = np.min(y)\n",
    "        y_mx = np.max(y)\n",
    "        if (x_mx - x_mn) > 10 and (y_mx - y_mn) > 10:\n",
    "            img = img[:,np.min(y):np.max(y)]\n",
    "    return img\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Remove black boundaries\n",
    "        if config.REMOVE_BLACK_BOUNDARIES:\n",
    "            img = remove_black_boundaries(img)\n",
    "        if aug:\n",
    "            transformed = train_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        mri_img.append(np.array(img))\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710de753-b2b6-429b-9fb3-6342f0694362",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8e056-9742-44d9-8be8-92905da94e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_prep = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-no-prep\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_no_prep.add_data(int(patient),                                            \n",
    "                      df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                      wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                      wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                      wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                      wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'No Pre-Processing Samples': data_no_prep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83170e-91c4-432c-9e38-b104c11908ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce7d36-91cd-45bd-af2e-81e0e2fe1252",
   "metadata": {},
   "source": [
    "## 2. Remove Black Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320b6019-737e-418c-ad95-00c98737a542",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d639b-f161-43f3-a04d-f1838e163f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Remove-Black\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520cf05c-c1e0-47b7-a1d3-f6efc5d35589",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d78cf-8fd6-4304-a7ac-dfa9e7103ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261c8c5-1ec7-410d-8e20-a5d25b04cdd5",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1843166-c319-45d9-b283-fa33b3c70c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec287c09-8343-4015-b3e2-178e71d97acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(img):\n",
    "    (x, y) = np.where(img > 0)\n",
    "    if len(x) > 0 and len(y) > 0:\n",
    "        x_mn = np.min(x)\n",
    "        x_mx = np.max(x)\n",
    "        y_mn = np.min(y)\n",
    "        y_mx = np.max(y)\n",
    "        if (x_mx - x_mn) > 10 and (y_mx - y_mn) > 10:\n",
    "            img = img[:,np.min(y):np.max(y)]\n",
    "    return img\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Remove black boundaries\n",
    "        if config.REMOVE_BLACK_BOUNDARIES:\n",
    "            img = remove_black_boundaries(img)\n",
    "        if aug:\n",
    "            transformed = train_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        mri_img.append(np.array(img))\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64240afb-77c8-4cf0-a95a-832479f87619",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c781f7c-034d-4e99-aa2a-621eab4a2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_remove_black = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-remove-black\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_remove_black.add_data(int(patient),                                            \n",
    "                               df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                               wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                               wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                               wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                               wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Removed Black Pixels Samples': data_remove_black})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a13b5-cd22-46d7-a276-90a866f3f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71805bea-0a64-46b2-94c2-5573f3fa8c70",
   "metadata": {},
   "source": [
    "## 3. Remove Black Boundaries II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9f387-a5e2-45ce-9dd0-512aa1c629a2",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb9e5f-b2e4-4412-b988-303e26b68955",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Remove-Black-II\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61850922-0afd-4351-b819-6a9d90abb724",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06478026-7fb4-4ee4-ac18-e915f9dcd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d71257-c8d8-4ade-a531-9ac219a9f9ab",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc1777d-999c-4059-9ecc-ee852be93c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122118a-e1dd-4090-be3e-e0f69a1b1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(img):\n",
    "    img = img[img.sum(1)!=0]\n",
    "    img = img.T[img.sum(0)!=0].T\n",
    "    return img\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Remove black boundaries\n",
    "        if config.REMOVE_BLACK_BOUNDARIES:\n",
    "            img = remove_black_boundaries(img)\n",
    "        if aug:\n",
    "            transformed = train_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        mri_img.append(np.array(img))\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f2f171-aeec-47dd-a02a-3f629dbc0472",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347790f-27ab-4e8c-84a0-a8c341c87122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_remove_black_ii = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-remove-black-ii\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_remove_black_ii.add_data(int(patient),                                            \n",
    "                                  df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                  wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Removed Black Pixels II Samples': data_remove_black_ii})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20ee11-09ac-4cbe-a1e0-2b58afc41cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e592c929-7051-4673-af97-efcc4b41ce4c",
   "metadata": {},
   "source": [
    "## 4. Remove Black Boundaries + Middle Slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb51dc3-148b-4f47-91bb-855e41e3bd16",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1d224-665c-4058-be37-5ae5ed18526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Middle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b95e4d-c6b9-4ebc-85d3-519ecd9f855b",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ea660-b1ce-47e5-ac1b-716859dc2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8aa93e-1b0d-4388-9523-3d97957bd0b3",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae8609-d39a-4ead-b511-6f40c77adf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd91f58-c9e2-4641-b5d2-da86fcaca191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(img):\n",
    "    img = img[img.sum(1)!=0]\n",
    "    img = img.T[img.sum(0)!=0].T\n",
    "    return img\n",
    "\n",
    "def get_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx, maximum_idx = get_idxs(mri_type)\n",
    "    # Create array which contains the images\n",
    "    mri_img = []\n",
    "    for file in mri_type[minimum_idx:maximum_idx]:\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Remove black boundaries\n",
    "        if config.REMOVE_BLACK_BOUNDARIES:\n",
    "            img = remove_black_boundaries(img)\n",
    "        if aug:\n",
    "            transformed = train_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        mri_img.append(np.array(img))\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfdda5-0383-4711-8653-0752654c8bd2",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a9ada-722c-4e5d-8511-d94ad3833f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_middle = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-middle\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_middle.add_data(int(patient),                                            \n",
    "                         df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                         wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                         wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                         wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                         wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Middle Samples': data_middle})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec7de4-1b57-4433-973b-99dc37b3d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c11271-b219-4224-a718-81492f8dda86",
   "metadata": {},
   "source": [
    "## 5. Remove Black Boundaries + x-th Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7126e2ee-e9ed-4cb0-928e-f963b176808b",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab8f74-c190-4e51-a079-d46913f1ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-xth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4569f8c-9d38-4093-b7fd-394dcd545a0f",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d3363-6a2d-413e-b6dc-d17c32e1f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e056a7-0110-4c61-b2ee-cac972bca5d8",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a307bf6-3cea-4507-957b-3a69f29adc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d91e0-a74a-4eea-a4b4-bb4485d038d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(img):\n",
    "    img = img[img.sum(1)!=0]\n",
    "    img = img.T[img.sum(0)!=0].T\n",
    "    return img\n",
    "\n",
    "def get_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Length of folder: {img_depth}\")\n",
    "    minimum_idx, maximum_idx, step = get_idxs(img_depth)\n",
    "    # Create array which contains the images\n",
    "    mri_img = []\n",
    "    counter = 0\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Remove black boundaries\n",
    "        if config.REMOVE_BLACK_BOUNDARIES:\n",
    "            img = remove_black_boundaries(img)\n",
    "        if aug:\n",
    "            transformed = train_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "            img = transformed[\"image\"]\n",
    "        mri_img.append(np.array(img))\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2862b-d7da-49bd-ad36-650fd2df15f7",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d41c7-b36f-4547-8db3-7668323b5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_th = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-x-th\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_x_th.add_data(int(patient),                                            \n",
    "                       df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                       wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'x-th Samples': data_x_th})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1652247-a580-447d-9ef0-414ce5fa054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a5c5b-fbd4-455f-b2e7-c398362b403e",
   "metadata": {},
   "source": [
    "## 6. Remove Black Boundaries III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1997f-fdd4-40f5-8eaa-f5271d174032",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28ceab-973a-4953-ae2c-39b83bd17d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Remove-Black-III\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ce332-8166-488d-b7fd-3d062eeab1f0",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c41219-7f4e-4f7b-86cc-176bf4875bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e791c6-be21-44ef-9d3e-16a40e675d4b",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e934b9f-0093-4878-a0d3-8e83c1933f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.ReplayCompose([\n",
    "    A.Resize(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c978322-d498-4b42-879f-de9c125ec5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def augmentation(imgs, aug):\n",
    "    resized_imgs = []\n",
    "    replay = None\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i,:,:]\n",
    "        if aug:\n",
    "            if replay:\n",
    "                transformed = A.ReplayCompose.replay(replay, image=img)\n",
    "            else:\n",
    "                transformed = train_transform(image=img)\n",
    "                replay = transformed['replay']\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "        img = transformed[\"image\"]\n",
    "        resized_imgs.append(np.array(img))\n",
    "    return np.array(resized_imgs)\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "    mri_img = np.array(mri_img)\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "    mri_img = augmentation(mri_img, aug)\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdc2e42-d7ee-4449-8b0d-52dfb94c9565",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42602c-c313-4d76-b9c1-d76398fb1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_remove_black_iii = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-remove-black-iii\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=True, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=True, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=True, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=True, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_remove_black_iii.add_data(int(patient),                                            \n",
    "                                  df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                  wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Removed Black Pixels III Samples': data_remove_black_iii})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f769d2-de00-4a65-83b8-a49126e632c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69261269-402b-40b6-84da-9eeed02b97bf",
   "metadata": {},
   "source": [
    "## 7. Combine Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648d1f7-8f94-4d49-a18c-d4ac26c67bfd",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c77fc-9306-417a-af41-d04bce169249",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Combining\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ab3b99-82bf-4724-84f8-a48cd06e5d60",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f8243-87be-4617-9bdd-a91f6aaacdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f3e142-7f93-4e84-9f38-e5501cd76eaa",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa09c45-e61c-45b0-b240-18acb7c4714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.ReplayCompose([\n",
    "    A.Resize(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520b8bd-fb5e-49fc-832c-5445d59038e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def augmentation(imgs, aug):\n",
    "    augmented_imgs = []\n",
    "    replay = None\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i,:,:]\n",
    "        if aug:\n",
    "            if replay:\n",
    "                transformed = A.ReplayCompose.replay(replay, image=img)\n",
    "            else:\n",
    "                transformed = train_transform(image=img)\n",
    "                replay = transformed['replay']\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "        img = transformed[\"image\"]\n",
    "        augmented_imgs.append(np.array(img))\n",
    "    return np.array(augmented_imgs)\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def get_middle_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    step = 1\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the 2D images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    if img_depth <= config.SLICE_NUMBER:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    elif img_depth <= config.SLICE_NUMBER*2:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    else:\n",
    "        minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black pixels\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "        \n",
    "    # Apply augmentation\n",
    "    mri_img = augmentation(mri_img, aug)\n",
    "    \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero)).astype(np.uint8)), axis = -1)\n",
    "        \n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d7e3c-2b74-4215-9520-1490558949cd",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3a0fd-35fd-4c16-80c8-5acdd20e0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combinig = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-combining\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_combinig.add_data(int(patient),                                            \n",
    "                                  df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                  wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                  wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Combining (Middle + x-th) Samples': data_combinig})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e816c05-f9bb-4573-bcbe-f25365cad223",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6c8a9-03bb-4fdb-a98e-79d746eee513",
   "metadata": {},
   "source": [
    "## 8. Average x slices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858e0d8-338b-4e57-a329-fc06aaadc6d1",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63d2d4-1156-4a7d-92e0-7d681171e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Albumentation\n",
    "    RRC_SIZE = 256,\n",
    "    RRC_MIN_SCALE = 0.85,\n",
    "    RRC_RATIO = (1., 1.),\n",
    "    CLAHE_CLIP_LIMIT = 2.0,\n",
    "    CLAHE_TILE_GRID_SIZE = (8, 8),\n",
    "    CLAHE_PROB = 0.50,\n",
    "    BRIGHTNESS_LIMIT = (-0.2,0.2),\n",
    "    BRIGHTNESS_PROB = 0.40,\n",
    "    HUE_SHIFT = (-15, 15),\n",
    "    SAT_SHIFT = (-15, 15),\n",
    "    VAL_SHIFT = (-15, 15),\n",
    "    HUE_PROB = 0.64,\n",
    "    COARSE_MAX_HOLES = 16,\n",
    "    COARSE_PROB = 0.7,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bcaab4-d528-493f-ad24-25777dfcd3c0",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc7d9b-573a-46ea-bd8a-d46f67b1e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969be272-bbb4-4ef9-938c-5aefe4edd51a",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af79dce-c9a3-47cd-a044-80c081c4e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.RandomResizedCrop(\n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    ),\n",
    "    A.CLAHE(\n",
    "        clip_limit=config.CLAHE_CLIP_LIMIT,\n",
    "        tile_grid_size=config.CLAHE_TILE_GRID_SIZE,\n",
    "        p=config.CLAHE_PROB\n",
    "    ),\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=config.BRIGHTNESS_LIMIT,\n",
    "        p=config.BRIGHTNESS_PROB\n",
    "    ),\n",
    "    A.HueSaturationValue(\n",
    "        hue_shift_limit=config.HUE_SHIFT, \n",
    "        sat_shift_limit=config.SAT_SHIFT, \n",
    "        val_shift_limit=config.VAL_SHIFT, \n",
    "        p=config.HUE_PROB\n",
    "    ),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=config.COARSE_MAX_HOLES,\n",
    "        p=config.COARSE_PROB),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.RandomResizedCrop( \n",
    "        config.RRC_SIZE, config.RRC_SIZE,            \n",
    "        scale=(config.RRC_MIN_SCALE, 1.0),\n",
    "        ratio=config.RRC_RATIO,\n",
    "        p=1.0\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93c363-55d3-4940-a270-d17bb3958e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def augmentation(imgs, aug):\n",
    "    resized_imgs = []\n",
    "    replay = None\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i,:,:]\n",
    "        if aug:\n",
    "            if replay:\n",
    "                transformed = A.ReplayCompose.replay(replay, image=img)\n",
    "            else:\n",
    "                transformed = train_transform(image=img)\n",
    "                replay = transformed['replay']\n",
    "        else:\n",
    "            transformed = valid_transform(image=img)\n",
    "        img = transformed[\"image\"]\n",
    "        resized_imgs.append(np.array(img))\n",
    "    return np.array(resized_imgs)\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    last_idx = minimum_idx\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        if i == minimum_idx:\n",
    "            files = [mri_type[i]]\n",
    "        else:\n",
    "            files = mri_type[last_idx+1:i+1]\n",
    "            last_idx = i\n",
    "        img_avg = None\n",
    "        for file in files:\n",
    "            if dicom:\n",
    "                img = dicom_2_image(file)\n",
    "            else:\n",
    "                img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img_avg is not None:\n",
    "                img_avg = (img_avg + img) / 2\n",
    "            else:\n",
    "                img_avg = img\n",
    "        mri_img.append(img_avg)\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black pixels\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "        \n",
    "    # Apply augmentation\n",
    "    mri_img = augmentation(mri_img, aug)\n",
    "    \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero)).astype(np.uint8)), axis = -1)\n",
    "        \n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2701fc28-e315-4001-bc74-4d966d49838f",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db53bd0-850b-4bd1-bdb6-d2cdf53387b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_average = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-average\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_average.add_data(int(patient),                                            \n",
    "                       df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                       wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                       wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Average Samples': data_average})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32c5ae-d41f-4e01-9723-4d60cfd1b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e940b54-3791-49d3-93a2-02a171afe496",
   "metadata": {},
   "source": [
    "## 9. Combine Slicing with TorchIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad881cd1-5b90-428d-9c85-b37916f355f1",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982560b6-32fc-491d-920c-b45ec82a4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Augmentation\n",
    "    SIZE = 256,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Combining-TorchIO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d470f83-e7f3-4147-b060-ff2a00393a0d",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db5b48-74bb-4a1d-9436-55e3bd746297",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0932d7-8588-4e71-9be2-ae249210ffef",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb573af3-024a-4271-8f92-a0e9377dda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def augmentation(img_3d):\n",
    "    downsampling_width = img_3d.shape[1] / config.SIZE\n",
    "    downsampling_height = img_3d.shape[2] / config.SIZE\n",
    "    downsampling_depth = img_3d.shape[3] / config.SLICE_NUMBER\n",
    "    \n",
    "    downsample = tio.Resample((downsampling_width, downsampling_height, downsampling_depth))\n",
    "    img_3d = downsample(img_3d)\n",
    "    return img_3d\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def get_middle_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    step = 1\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the 2D images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    if img_depth <= config.SLICE_NUMBER:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    elif img_depth <= config.SLICE_NUMBER*2:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    else:\n",
    "        minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "\n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black pixels\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "        \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3) # From depthx256x256 to 256x256xdepth\n",
    "    mri_img = np.expand_dims(mri_img, axis=0)\n",
    "    \n",
    "    # Augmentation\n",
    "    mri_img = augmentation(mri_img)\n",
    "    \n",
    "    # Reshape again\n",
    "    mri_img = mri_img.reshape(config.SIZE, config.SIZE, config.SLICE_NUMBER)\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero)).astype(np.uint8)), axis = -1)\n",
    "        \n",
    "    if config.VERBOSE:\n",
    "        print(f\"Shape of mri_img: {mri_img.shape}\")\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088014f6-ded7-4eb0-a76f-960d5ff69cc9",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3daa99-febe-4db1-a677-9951925b7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combinig_torchio = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-combining-torchio\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_combinig_torchio.add_data(int(patient),                                            \n",
    "                                   df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                   wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Combining (Middle + x-th) with TorchIO Samples': data_combinig_torchio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a67c65-2ae2-4681-9948-767860cd62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657e0d2-2e5b-4016-8e43-477f790e86e7",
   "metadata": {},
   "source": [
    "## 10. 3D-Wise Remove Black Pixels + Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fbe8a-3266-4055-a5d9-371a7c1fa1e1",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f54916-e7a3-4074-93c0-e5c59cb68a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Augmentation\n",
    "    SIZE = 256,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-No-Normalization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4139809b-7568-416d-a6f4-4e82ee801b4a",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52b209-d4a4-4c2c-8e62-89004817876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619087ba-d4b4-44d6-9b8c-0f276952d97d",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8cc00-7bd2-4a3f-bd12-ee48ad3f2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augmentation(img, width, height, depth):\n",
    "\n",
    "    train_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1))                                  # Rescale between 0 and 1\n",
    "    ])\n",
    "    \n",
    "    return train_transform(img) \n",
    "\n",
    "def valid_augmentation(img, width, height, depth):\n",
    "\n",
    "    valid_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1))                                  # Rescale between 0 and 1\n",
    "    ])\n",
    "    \n",
    "    return valid_transform(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343514c7-875c-4edf-becf-c7159fed3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def get_middle_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    step = 1\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the 2D images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    if img_depth <= config.SLICE_NUMBER:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    elif img_depth <= config.SLICE_NUMBER*2:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    else:\n",
    "        minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "    \n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    counter = 0\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "        counter += 1\n",
    "        if counter == config.SLICE_NUMBER:\n",
    "            break\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black boundaries\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "    \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3)  # From depthxwidthxheight to widthxheightxdepth\n",
    "    mri_img = np.expand_dims(mri_img, axis=0)  # Expand to 1xwidthxheightxdepth\n",
    "    \n",
    "    # Augmentation\n",
    "    downsampling_width = mri_img.shape[1] / config.SIZE\n",
    "    downsampling_height = mri_img.shape[2] / config.SIZE\n",
    "    downsampling_depth = mri_img.shape[3] / config.SLICE_NUMBER\n",
    "    if aug:\n",
    "        mri_img = train_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "    else:\n",
    "        mri_img = valid_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "        \n",
    "    # Reshape again (for saving purposes only in this notebook)\n",
    "    mri_img = mri_img.reshape(config.SIZE, config.SIZE, config.SLICE_NUMBER)\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero))), axis = -1)\n",
    "        \n",
    "    mri_img = mri_img.astype(int)\n",
    "        \n",
    "    # Normalization (and turn into float64))\n",
    "    #mri_img = (mri_img - np.mean(mri_img, axis=(0,1)))/np.std(mri_img, axis=(0,1))\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4ba1f-9c95-4faf-8cb3-c71ccad39d8b",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2536528-4e9d-4216-8e17-b9458fa4eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_normalization = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-data-nonormalization\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_no_normalization.add_data(int(patient),                                            \n",
    "                                   df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                   wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'No Normalization': data_no_normalization})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dac8777-986f-4059-badf-c5b4a7e8469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c03887-47a3-4227-88f5-ff9b2eff5862",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d7e06d-5528-4f66-9e31-742193a72e7f",
   "metadata": {},
   "source": [
    "## 11. 3D-Wise Remove Black Pixels + Z-Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4dff0f-b1ca-4057-a681-98421bf6e0e7",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33be780c-4691-44da-b58f-f7e2b137a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Augmentation\n",
    "    SIZE = 256,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Z-Normalization-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc1de0-74b2-492c-8972-afa8615cf23e",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be9264-5533-4570-8a8c-1fab04cfc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d2625-693c-4a07-9c6b-f4e8d8309581",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7282493-e516-47b7-abab-3b300113f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augmentation(img, width, height, depth):\n",
    "\n",
    "    train_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1)),                                 # Rescale between 0 and 1\n",
    "        tio.ZNormalization() # Z-Normalization: Subtract mean and divide by std\n",
    "    ])\n",
    "    \n",
    "    return train_transform(img) \n",
    "\n",
    "def valid_augmentation(img, width, height, depth):\n",
    "\n",
    "    valid_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1)),                                 # Rescale between 0 and 1\n",
    "        tio.ZNormalization() # Z-Normalization: Subtract mean and divide by std\n",
    "    ])\n",
    "    \n",
    "    return valid_transform(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b931e9d4-f6b5-4b26-aa47-aef7baf0c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def get_middle_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    step = 1\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the 2D images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    if img_depth <= config.SLICE_NUMBER:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    elif img_depth <= config.SLICE_NUMBER*2:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    else:\n",
    "        minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "    \n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    counter = 0\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "        counter += 1\n",
    "        if counter == config.SLICE_NUMBER:\n",
    "            break\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black boundaries\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "    \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3)  # From depthxwidthxheight to widthxheightxdepth\n",
    "    mri_img = np.expand_dims(mri_img, axis=0)  # Expand to 1xwidthxheightxdepth\n",
    "    \n",
    "    # Augmentation\n",
    "    downsampling_width = mri_img.shape[1] / config.SIZE\n",
    "    downsampling_height = mri_img.shape[2] / config.SIZE\n",
    "    downsampling_depth = mri_img.shape[3] / config.SLICE_NUMBER\n",
    "    if aug:\n",
    "        mri_img = train_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "    else:\n",
    "        mri_img = valid_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "        \n",
    "    # Reshape again (for saving purposes only in this notebook)\n",
    "    mri_img = mri_img.reshape(config.SIZE, config.SIZE, config.SLICE_NUMBER)\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero))), axis = -1)\n",
    "        \n",
    "    # Normalization (and turn into float64))\n",
    "    #mri_img = (mri_img - np.mean(mri_img, axis=(0,1)))/np.std(mri_img, axis=(0,1))\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187e8c1-9e03-4693-8fa4-6cdf903266c8",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be74ee7-bb75-407d-8e09-904322ba04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_z_normalization = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-data-z-normalization\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_z_normalization.add_data(int(patient),                                            \n",
    "                                   df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                   wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Z Normalization': data_z_normalization})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b389ef87-17af-480f-9d98-f21ab2163b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296971e8-f727-4c08-bc30-d3827ed7bc30",
   "metadata": {},
   "source": [
    "## 12. 3D-Wise Remove Black Pixels + 3D CLAHE Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81fa00-2e75-4048-96e7-5650af06b20f",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ad4bd-3206-487b-b7a1-6b25c532fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    # Pre-processing\n",
    "    SLICE_NUMBER = 32, # >= 30\n",
    "    REMOVE_BLACK_BOUNDARIES = True,\n",
    "    DICOM=False,\n",
    "    \n",
    "    # Augmentation\n",
    "    SIZE = 256,\n",
    "    \n",
    "    # Logging\n",
    "    VERBOSE = False,\n",
    "    NAME = \"00_EDA_Slicing-Clahe-Normalization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e67d1-862e-42d7-988a-1b249eb2689b",
   "metadata": {},
   "source": [
    "#### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa737c8-1edc-41fc-9464-37fe5cdc032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=\"uzk-wim\", project='rsna-miccai-slicing', config=config, mode=\"online\")\n",
    "config = wandb.config\n",
    "wandb.run.name = f\"{config.NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f396207-53b7-4989-9329-3093b8fcd6c8",
   "metadata": {},
   "source": [
    "### 1. Loading Images\n",
    "\n",
    "#### 1.1 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a8b058-eb11-44f0-b04e-f5183cf11366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augmentation(img, width, height, depth):\n",
    "\n",
    "    train_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1))                                  # Rescale between 0 and 1\n",
    "    ])\n",
    "    \n",
    "    return train_transform(img) \n",
    "\n",
    "def valid_augmentation(img, width, height, depth):\n",
    "\n",
    "    valid_transform = tio.Compose([\n",
    "        tio.Resample((width, height, depth)),                         # Resample (resize) image\n",
    "        tio.RescaleIntensity((0, 1))                                  # Rescale between 0 and 1\n",
    "    ])\n",
    "    \n",
    "    return valid_transform(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0abbd0e-9f2c-4eaa-8971-70035e618d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicom_2_image(file, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(file)\n",
    "    # VOI LUT (if available by DICOM device) is used to\n",
    "    # transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        img = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        img = dicom.pixel_array\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        img = np.amax(img) - img\n",
    "    \n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def remove_black_boundaries(imgs):\n",
    "    min=np.array(np.nonzero(imgs)).min(axis=1)\n",
    "    max=np.array(np.nonzero(imgs)).max(axis=1)\n",
    "    return imgs[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n",
    "\n",
    "def get_middle_idxs(mri_type):\n",
    "    # Take SLICE_NUMBER slices from the middle\n",
    "    threshold = config.SLICE_NUMBER // 2\n",
    "    minimum_idx = len(mri_type)//2 - threshold if (len(mri_type)//2 - threshold) > 0 else 0\n",
    "    maximum_idx = len(mri_type)//2 + threshold  # maximum can exceed the index\n",
    "    step = 1\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_xth_idxs(img_depth):\n",
    "    minimum_idx = 0\n",
    "    maximum_idx = img_depth\n",
    "    step = 1\n",
    "    if config.SLICE_NUMBER < img_depth:\n",
    "        mod = img_depth % config.SLICE_NUMBER\n",
    "        threshold = int(mod // 2)\n",
    "        minimum_idx = threshold\n",
    "        maximum_idx = img_depth - threshold\n",
    "        step = img_depth // config.SLICE_NUMBER\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Minimum {minimum_idx}\")\n",
    "        print(f\"Maximum {maximum_idx}\")\n",
    "        print(f\"Step size: {step}\")\n",
    "    return minimum_idx, maximum_idx, step\n",
    "\n",
    "def get_3d_image(mri_type, aug, dicom):\n",
    "    # Calculate the indices of the 2D images which should be considered for the 3D image\n",
    "    img_depth = len(mri_type)\n",
    "    if img_depth <= config.SLICE_NUMBER:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    elif img_depth <= config.SLICE_NUMBER*2:\n",
    "        minimum_idx, maximum_idx, step = get_middle_idxs(mri_type)\n",
    "    else:\n",
    "        minimum_idx, maximum_idx, step = get_xth_idxs(img_depth)\n",
    "    \n",
    "    # Create list which contains all the 2D images which form the 3D image\n",
    "    mri_img = []\n",
    "    counter = 0\n",
    "    for i in range(minimum_idx, maximum_idx, step):\n",
    "        if i >= len(mri_type):\n",
    "            break\n",
    "        file = mri_type[i]\n",
    "        if dicom:\n",
    "            img = dicom_2_image(file)\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        mri_img.append(img)\n",
    "        counter += 1\n",
    "        if counter == config.SLICE_NUMBER:\n",
    "            break\n",
    "    mri_img = np.array(mri_img)\n",
    "    \n",
    "    # Remove black boundaries\n",
    "    if config.REMOVE_BLACK_BOUNDARIES:\n",
    "        mri_img = remove_black_boundaries(mri_img)\n",
    "    \n",
    "    # Reshape\n",
    "    mri_img = np.rollaxis(np.array(mri_img), 0, 3)  # From depthxwidthxheight to widthxheightxdepth\n",
    "    mri_img = np.expand_dims(mri_img, axis=0)  # Expand to 1xwidthxheightxdepth\n",
    "    \n",
    "    # Augmentation\n",
    "    downsampling_width = mri_img.shape[1] / config.SIZE\n",
    "    downsampling_height = mri_img.shape[2] / config.SIZE\n",
    "    downsampling_depth = mri_img.shape[3] / config.SLICE_NUMBER\n",
    "    if aug:\n",
    "        mri_img = train_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "    else:\n",
    "        mri_img = valid_augmentation(mri_img, downsampling_width, downsampling_height, downsampling_depth)\n",
    "        \n",
    "    # Reshape again (for saving purposes only in this notebook)\n",
    "    mri_img = mri_img.reshape(config.SIZE, config.SIZE, config.SLICE_NUMBER)\n",
    "    \n",
    "    mri_img = mclahe(mri_img)\n",
    "    \n",
    "    # If less than SLICE_NUMBER slices, add SLICE_NUMBER - mri_img.shape[-1] slices with only zero values\n",
    "    if mri_img.shape[-1] < config.SLICE_NUMBER:\n",
    "        if config.VERBOSE:\n",
    "            print(f\"Current slices: {mri_img.shape[-1]}\")\n",
    "        n_zero = config.SLICE_NUMBER - mri_img.shape[-1]\n",
    "        mri_img = np.concatenate((mri_img, np.zeros((config.RRC_SIZE, config.RRC_SIZE, n_zero))), axis = -1)\n",
    "        \n",
    "    # Normalization (and turn into float64))\n",
    "    #mri_img = (mri_img - np.mean(mri_img, axis=(0,1)))/np.std(mri_img, axis=(0,1))\n",
    "    return mri_img\n",
    "\n",
    "def load_images(scan_id, mri_type, aug=True, split=\"train\", dicom=False):\n",
    "    file_ext = \"png\"\n",
    "    if dicom:\n",
    "        file_ext = \"dcm\"\n",
    "    if config.VERBOSE:\n",
    "        print(f\"Scan id {scan_id}\")\n",
    "        \n",
    "    # Ascending sort\n",
    "    if mri_type == \"FLAIR\":\n",
    "        flair = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/FLAIR/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(flair, aug, dicom)\n",
    "    elif mri_type == \"T1w\":\n",
    "        t1w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1w, aug, dicom)\n",
    "    elif mri_type == \"T1wCE\":\n",
    "        t1wce = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T1wCE/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t1wce, aug, dicom)\n",
    "    else:\n",
    "        t2w = sorted(glob.glob(f\"{PATH}/{split}/{scan_id}/T2w/*.{file_ext}\"), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        img = get_3d_image(t2w, aug, dicom)\n",
    "    \n",
    "    # Return 3D image: WidthxHeightxDepth\n",
    "    # Data type: uint8\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd28ffb-b93c-474e-a5d8-459f09d043d9",
   "metadata": {},
   "source": [
    "#### 1.2 Load, Save & Store Images (in Weights and Biases) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f11f15-49b4-45e9-a5f4-98e9f9e8a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clahe_normalization = wandb.Table(columns=['patient_id', 'target', 'FLAIR', 'T1w', 'T1wCE', 'T2w'])\n",
    "path = \"../tmp/tmp-gifs-data-clahe-normalization\"\n",
    "\n",
    "for patient in sample_patients:\n",
    "    img_flair =load_images(patient, mri_type=\"FLAIR\", aug=False, dicom=config.DICOM)\n",
    "    img_t1w =load_images(patient, mri_type=\"T1w\", aug=False, dicom=config.DICOM)\n",
    "    img_t1wce =load_images(patient, mri_type=\"T1wCE\", aug=False, dicom=config.DICOM)\n",
    "    img_t2w =load_images(patient, mri_type=\"T2w\", aug=False, dicom=config.DICOM)\n",
    "    \n",
    "    imgs_flair = []\n",
    "    for i in range(img_flair.shape[2]):\n",
    "        imgs_flair.append(img_flair[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_flair.gif', imgs_flair)\n",
    "        \n",
    "    imgs_t1w = []\n",
    "    for i in range(img_t1w.shape[2]):\n",
    "        imgs_t1w.append(img_t1w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1w.gif', imgs_t1w)\n",
    "        \n",
    "    imgs_t1wce = []\n",
    "    for i in range(img_t1wce.shape[2]):\n",
    "        imgs_t1wce.append(img_t1wce[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t1wce.gif', imgs_t1wce)\n",
    "        \n",
    "    imgs_t2w = []\n",
    "    for i in range(img_t2w.shape[2]):\n",
    "        imgs_t2w.append(img_t2w[:,:,i])\n",
    "    imageio.mimsave(f'{path}/{patient}_t2w.gif', imgs_t2w)\n",
    "    \n",
    "    data_clahe_normalization.add_data(int(patient),                                            \n",
    "                                   df_train.loc[df_train.BraTS21ID == int(patient)].MGMT_value.values[0],\n",
    "                                   wandb.Image(f'{path}/{patient}_flair.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1w.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t1wce.gif'),\n",
    "                                   wandb.Image(f'{path}/{patient}_t2w.gif'))\n",
    "    \n",
    "wandb.log({'Clahe Normalization': data_clahe_normalization})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10484041-170f-473f-8de9-d552917c361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8011a899-1498-468b-bddc-5e1a3116e250",
   "metadata": {},
   "source": [
    "Done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: Kaggle]",
   "language": "python",
   "name": "kaggle_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
